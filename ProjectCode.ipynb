{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "676f9a1e",
      "metadata": {
        "id": "676f9a1e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import warnings\n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "from pthflops import count_ops\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d44679e4",
      "metadata": {
        "id": "d44679e4"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/Natural-Faces.zip                                         # CODE TO MOVE IMAGES FROM ONE FOLDER TO ANOTHER\n",
        "# import os, random\n",
        "# import shutil\n",
        "\n",
        "# m=10\n",
        "\n",
        "# src_dir = \"C:/Users/occul/Desktop/Datasets/Natural-Faces/train/contempt/\"\n",
        "# dst_dir = \"C:/Users/occul/Desktop/Datasets/Natural-Faces/test/contempt/\"\n",
        "\n",
        "# file_list = os.listdir(src_dir)\n",
        "\n",
        "# for i in range(m):\n",
        "    \n",
        "#     a = random.choice(file_list)\n",
        "#         #file_list.remove(a)\n",
        "#     shutil.move(src_dir + a, dst_dir+ a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "61417d86",
      "metadata": {
        "id": "61417d86"
      },
      "outputs": [],
      "source": [
        "def load_data(train_path, test_path, batch_size,input_size,mn,sd,shuffle_test=False):\n",
        "    \n",
        "    ######## Write your code here ########\n",
        "    transform_dict={\"src\":transforms.Compose([transforms.Resize(size=input_size),transforms.RandomHorizontalFlip(),transforms.RandomAdjustSharpness(sharpness_factor=0.3),\n",
        "            transforms.RandomVerticalFlip(),transforms.ToTensor(),])}\n",
        "\n",
        "    train=datasets.ImageFolder(root=train_path,transform=transform_dict[\"src\"])\n",
        "    \n",
        "    \n",
        "    labelslist=train.class_to_idx\n",
        "    dataset_size = len(train)\n",
        "    \n",
        "    train_size = int(round(0.85 * dataset_size))\n",
        "    val_size = int(round(0.15 * dataset_size))\n",
        "    \n",
        "\n",
        "    train_dataset,val_dataset = torch.utils.data.random_split(train,[train_size,val_size])\n",
        "    test_dataset=datasets.ImageFolder(root=test_path,transform=transform_dict[\"src\"])\n",
        "#     transform=transform_dict[\"src\"]\n",
        "    \n",
        "\n",
        "    print('Size Of Train Dataset',len(train_dataset))\n",
        "    print('Size Of Test Dataset',len(test_dataset))\n",
        "    print('Size Of Validation Dataset',len(val_dataset))\n",
        "   \n",
        "\n",
        "    data_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "    shuffle=True, drop_last=False,num_workers=0)\n",
        "    data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "    shuffle=False, drop_last=False,num_workers=0)\n",
        "    data_loader_val = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
        "    shuffle=True, drop_last=False,num_workers=0)\n",
        " \n",
        "      \n",
        "    return data_loader_train, data_loader_test,data_loader_val,labelslist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83844acb",
      "metadata": {
        "id": "83844acb"
      },
      "outputs": [],
      "source": [
        "# model1=models.resnet50(weights=True)               # FINDING NO OF LAYERS IN A MODEL AND DISPLAYING THEM\n",
        "# ct=0\n",
        "# for child in model1.children():\n",
        "#     ct+=1\n",
        "#     print('--------------')\n",
        "#     print(child)\n",
        "# print(ct)\n",
        "\n",
        "\n",
        "model_vgg_frozen = models.vgg16(weights=True)         # CREATING MODELS FREEZING ALL THE LAYERS EXCEPT THE FC LAYER\n",
        "ct = 0\n",
        "for child in model_vgg_frozen.children():\n",
        "    ct += 1\n",
        "    if ct < 3:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "            \n",
        "model_resnet_frozen = models.resnet50(weights=True)\n",
        "ct = 0\n",
        "for child in model_resnet_frozen.children():\n",
        "    ct += 1\n",
        "    if ct < 10:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6eb59af6",
      "metadata": {},
      "outputs": [],
      "source": [
        "modelvggconv = torchvision.models.vgg16(weights=False)\n",
        "feats_list = list(modelvggconv.features)\n",
        "new_feats_list = []\n",
        "for feat in feats_list:\n",
        "            new_feats_list.append(feat)\n",
        "            if isinstance(feat, nn.Conv2d):\n",
        "                new_feats_list.append(nn.Dropout(p=0.2,inplace=False))\n",
        "\n",
        "# modify convolution layers\n",
        "modelvggconv.features = nn.Sequential(*new_feats_list)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "modelvggrelu = torchvision.models.vgg16(weights=False)\n",
        "\n",
        "feats_list = list(modelvggrelu.features)\n",
        "new_feats_list = []\n",
        "for feat in feats_list:\n",
        "            new_feats_list.append(feat)\n",
        "            if isinstance(feat, nn.ReLU):\n",
        "                new_feats_list.append(nn.Dropout(p=0.2,inplace=False))\n",
        "\n",
        "# modify convolution layers\n",
        "modelvggrelu.features = nn.Sequential(*new_feats_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1f28fa02",
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_mean_and_sd(loader):\n",
        "    \n",
        "    cnt = 0\n",
        "    fst_moment = torch.empty(3)\n",
        "    snd_moment = torch.empty(3)\n",
        "\n",
        "    for images, _ in loader:\n",
        "        b, c, h, w = images.shape\n",
        "        nb_pixels = b * h * w\n",
        "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
        "        sum_of_square = torch.sum(images ** 2,\n",
        "                                  dim=[0, 2, 3])\n",
        "        fst_moment = (cnt * fst_moment + sum_) / (\n",
        "                      cnt + nb_pixels)\n",
        "        snd_moment = (cnt * snd_moment + sum_of_square) / (\n",
        "                            cnt + nb_pixels)\n",
        "        cnt += nb_pixels\n",
        "\n",
        "    mean, std = fst_moment, torch.sqrt(\n",
        "      snd_moment - fst_moment ** 2)        \n",
        "    return mean,std\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "613b1935",
      "metadata": {
        "id": "613b1935"
      },
      "outputs": [],
      "source": [
        "def img_show(train_loader,lablist):\n",
        "\n",
        "    \n",
        "    \n",
        "    images,labels=next(iter(train_loader))\n",
        "    \n",
        "    print(f\"Images batch shape: {images.size()}\")\n",
        "    print(f\"Labels batch shape: {labels.size()}\")\n",
        "    print(lablist)\n",
        "    \n",
        "    figure = plt.figure(figsize=(5, 5))\n",
        "    cols, rows = 3, 3             #Displays 9 images in a 3*3 grid\n",
        "    for i in range(1, cols * rows + 1):\n",
        "\n",
        "        img = images[i].squeeze()\n",
        "        img_label = labels[i]\n",
        "        \n",
        "        label=(list(lablist.keys())[list(lablist.values()).index(img_label)])\n",
        "        \n",
        "        figure.add_subplot(rows, cols, i)\n",
        "        plt.title(label)\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(img.permute(1,2,0))\n",
        "    plt.show()\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "zMKMfg049nY2",
      "metadata": {
        "id": "zMKMfg049nY2"
      },
      "outputs": [],
      "source": [
        "def grp_show(x,y,label,col,x_label,y_label,title,path):\n",
        "    \n",
        "    for i in range(0,len(y)):\n",
        "      plt.plot(x, y[i], col[i], label=label[i])\n",
        "    \n",
        "    plt.title(title)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.savefig(f'{path}{title}.jpg')\n",
        "    \n",
        "    plt.show()\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4fb2d8f8",
      "metadata": {
        "id": "4fb2d8f8"
      },
      "outputs": [],
      "source": [
        "def train_model(num_epochs,train_loader,val_loader):\n",
        "    model.train()\n",
        "    Train_steps = len(train_loader)\n",
        "    Val_steps=len(val_loader)\n",
        "    print('Total Steps',Train_steps)\n",
        "    t1 = time.time()\n",
        "\n",
        "    acclist_train=[]\n",
        "    acclist_val=[]\n",
        "    losslist_train=[]\n",
        "    losslist_val=[]\n",
        "    epc=[]\n",
        "    cons_epchs=0\n",
        "    loss_criteria=0.0001\n",
        "    last_loss=np.Inf\n",
        "    verbose=10\n",
        "    \n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # exp_lr_scheduler.step()\n",
        "        # print('Epoch:', epoch+1,'LR:', exp_lr_scheduler.get_lr())\n",
        "        \n",
        "        \n",
        "        correct=0\n",
        "        total=0\n",
        "        loss_train=0\n",
        "        for i, data in enumerate(train_loader):\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)#Feedforward\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()#Gradient\n",
        "            loss.backward()#Weights update\n",
        "            optimizer.step()\n",
        "\n",
        "            total+= labels.size(0) \n",
        "\n",
        "            _,predicted = torch.max(outputs.data, 1) #1 so that all the data is on the same line\n",
        "\n",
        "            correct+= (predicted == labels).sum().item()\n",
        "            loss_train+=loss.item()\n",
        "            if (i + 1)  == Train_steps:\n",
        "\n",
        "                  correct_v = 0                                                 #Validation Loop\n",
        "                  total_v = 0\n",
        "                  loss_v=0\n",
        "                  for dataVal in val_loader:\n",
        "                      images_v, labels_v = dataVal[0].to(device), dataVal[1].to(device)\n",
        "                      outputs_v = model(images_v)\n",
        "                      loss=criterion(outputs_v,labels_v)\n",
        "                      _, predicted_v = torch.max(outputs_v.data, 1)\n",
        "                      correct_v += (predicted_v == labels_v).sum().item()\n",
        "                      total_v += labels_v.size(0)\n",
        "                      loss_v+=loss.item()\n",
        "              \n",
        "                  print('Epoch [{}/{}], Training Loss: {:.4f}, Validation Loss: {:.4f}, Training Accuracy: {:.2f}%, Validation Accuracy: {:.4f},'\n",
        "                      .format(epoch + 1, num_epochs, loss_train/Train_steps, loss_v/Val_steps, (correct / total) * 100, (correct_v / total_v) * 100))\n",
        "                  \n",
        "                  acclist_train.append((correct / total) * 100)\n",
        "                  acclist_val.append((correct_v / total_v) * 100)\n",
        "                  losslist_train.append(loss_train/Train_steps)\n",
        "                  losslist_val.append(loss_v/Val_steps)\n",
        "                  epc.append(epoch+1)\n",
        "\n",
        "                  \n",
        "                  \n",
        "                  current_loss=loss_v/Val_steps\n",
        "\n",
        "                  if (last_loss-current_loss)<=loss_criteria:\n",
        "                      cons_epchs += 1\n",
        "                      last_loss = current_loss\n",
        "                      \n",
        "                      if cons_epchs >= verbose:\n",
        "                        print('Loss Did Not Improve by more than 0.0001 for 10 epochs..Stopping')\n",
        "                        print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))\n",
        "                        return model,acclist_train,acclist_val,losslist_train,losslist_val,epc\n",
        "\n",
        "                  else:\n",
        "                    cons_epchs = 0\n",
        "\n",
        "                  \n",
        "\n",
        " \n",
        "    time_taken=time.time()-t1\n",
        "    print(\"######## Training Finished in {} seconds ###########\".format(time_taken))\n",
        "    return model,acclist_train,acclist_val,losslist_train,losslist_val,epc,time_taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bcf51d71",
      "metadata": {
        "id": "bcf51d71"
      },
      "outputs": [],
      "source": [
        "from torch.cuda import device\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "\n",
        "def test_model(model,test_loader):\n",
        "    model.eval() \n",
        "\n",
        "    predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "    lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "\n",
        "    with torch.no_grad(): \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data in test_loader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            predlist=torch.cat([predlist,predicted.view(-1).cpu()])\n",
        "            lbllist=torch.cat([lbllist,labels.view(-1).cpu()])\n",
        "        \n",
        "        \n",
        "        print('Test Accuracy of the model on the {} test images: {} %'.format(total, (correct / total) * 100))\n",
        "        conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
        "        ConfusionMatrixDisplay(conf_mat).plot()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9737c916",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "9737c916",
        "outputId": "b5660876-2e71-4e67-e6f0-30d8d9057bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size Of Train Dataset 3959\n",
            "Size Of Test Dataset 900\n",
            "Size Of Validation Dataset 699\n",
            "mean and std: \n",
            " tensor([0.5220, 0.5220, 0.5220]) tensor([0.2296, 0.2296, 0.2296])\n",
            "Size Of Train Dataset 27736\n",
            "Size Of Test Dataset 9837\n",
            "Size Of Validation Dataset 4894\n",
            "mean and std: \n",
            " tensor([0.5420, 0.4671, 0.4346]) tensor([0.2645, 0.2481, 0.2500])\n",
            "Size Of Train Dataset 14531\n",
            "Size Of Test Dataset 4250\n",
            "Size Of Validation Dataset 2564\n",
            "mean and std: \n",
            " tensor([0.4657, 0.5203, 0.5741]) tensor([0.2417, 0.2425, 0.2719])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_paths=['D:/Datasets/Natural-Faces/train/','D:/Datasets/tiny/train/','D:/Datasets/Masked-fer2013/train/']\n",
        "test_paths=['D:/Datasets/Natural-Faces/test/','D:/Datasets/tiny/test/','D:/Datasets/Masked-fer2013/test/']\n",
        "\n",
        "mdl_path='D:/Datasets/Models/'\n",
        "img_path='D:/Datasets/Images/'  # CHANGE ALL 4 PATHS BASED ON UR FOLDER LOCATIONS (FOR MODEL/IMG PATH MAKE SURE TO CREATE FOLDERS)\n",
        "\n",
        "mn=[[0.5220, 0.5220, 0.5220],[0.5420, 0.4671, 0.4346],[0.4657, 0.5203, 0.5741]]\n",
        "sd=[[0.2296, 0.2296, 0.2296],[0.2645, 0.2481, 0.2500],[0.2417, 0.2425, 0.2719]]\n",
        "\n",
        "\n",
        "batch_size=64\n",
        "image_size=(48,48)\n",
        "num_epochs=100\n",
        "learning_rate=0.0001\n",
        "\n",
        "dtaname=['Natural-Faces','Tiny','Fer-Masked','Fer']\n",
        "\n",
        "# mdls=[torchvision.models.shufflenet_v2_x0_5(),torchvision.models.mobilenet_v3_small(),torchvision.models.mobilenet_v2(),torchvision.models.mnasnet0_5()]\n",
        "# mdlname=['Shufflnet','MobileNetV3','MobileNetv2','MnasNet'] \n",
        "\n",
        "mdls=[torchvision.models.vgg16(weights=True),model_vgg_frozen,torchvision.models.resnet50(weights=True),model_resnet_frozen]  # CHANGE THIS ACCORDING TO NEED\n",
        "mdlname=['VGG-16 Fine_tuning','VGG16 Deep_tuning','Resnet Fine_tuning','Resnet Deep_tuning'] # UPDATE BASED ON LIST ABOVE\n",
        "\n",
        "# mdls=[modelvggconv,modelvggrelu]\n",
        "# mdlname=['Conv','Relu']\n",
        "\n",
        "\n",
        "for i in range(0,len(train_paths)):\n",
        "    for k in range (0,len(mdls)):\n",
        "        \n",
        "        train_folder=train_paths[i]\n",
        "        test_folder=test_paths[i]\n",
        "        train_loader,test_loader,val_loader,lablist=load_data(train_folder,test_folder,batch_size,image_size,mn[i],sd[i])\n",
        "        \n",
        "        mean, std = batch_mean_and_sd(train_loader)\n",
        "        print(\"mean and std: \\n\", mean, std)\n",
        "        \n",
        "        img_show(train_loader,lablist)\n",
        "        model=mdls[k]#model reinitialized to prevent transfer learning on the other data sets\n",
        "        \n",
        "        \n",
        "        # print(model)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        # exp_lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer=optimizer,step_size=5,gamma=0.5) # SCHEDULED LEARNING RATE\n",
        "\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(\"Device: {}\".format(device))\n",
        "        model.to(device)\n",
        "        \n",
        "        # print('----------PARAMETERS----------') #PRINTING MODEL AND NO OF PARAMTERS FOR A GIVEN INPUT SIZE\n",
        "        # summary(model, (3,48,48))\n",
        "        # print('----------FLOPS----------')\n",
        "        # count_ops(model, torch.rand(1,3,48,48).to(device))\n",
        "        \n",
        "        \n",
        "        model,t_acc,v_acc,t_loss,v_loss,epc,time_taken=train_model(num_epochs,train_loader,val_loader) # TRAINING MODEL\n",
        "        \n",
        "        time_taken=round((time_taken/60),2)\n",
        "        title=mdlname[k]+' '+dtaname[i]\n",
        "        \n",
        "        grp_show(epc,[t_acc,v_acc],['Training','Valiation'],['b','r'],'Epochs ('+str(time_taken)+' minutes)','Accuracies','Accuracy Comparision '+title,img_path) #DISPLAYING AND STORING GRAPHS\n",
        "        grp_show(epc,[t_loss,v_loss],['Training','Valiation'],['b','r'],'Epochs ('+str(time_taken)+' minutes)','Losses','Loss Comparision '+title,img_path)\n",
        "    \n",
        "        test_model(model,test_loader)  # TESTING MODEL\n",
        "        torch.save(model, mdl_path+title) # SAVING MODEL\n",
        "        torch.cuda.empty_cache() \n",
        "\n",
        "    \n",
        "    \n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "cb4b99fcf2629cf60d9f79434a99c23f0b4cecdc979d9a01295b1b3403a9be66"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
